{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "# Create vocab of chars\n",
    "# Read windows and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 5447744\n"
     ]
    }
   ],
   "source": [
    "with open('data/shakespeare.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "print(type(text), len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7469\n",
      "3599\n"
     ]
    }
   ],
   "source": [
    "sonnets = re.split(r'\\n\\n', text)\n",
    "print(len(sonnets))\n",
    "sonnets = [s for s in sonnets if s.count('\\n') > 1]\n",
    "print(len(sonnets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sonnet(text):\n",
    "    text = re.sub(r'[\\d`{}|&_<>]', '', text)\n",
    "    text = '\\n'.join([l.strip() for l in text.split('\\n') if l.strip() != ''])\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = [clean_sonnet(s) for s in sonnets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4861240 from faire\n"
     ]
    }
   ],
   "source": [
    "text = ''.join(sonnets)\n",
    "print(len(text), text[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 809184), ('e', 434393), ('t', 322113), ('o', 309204), ('a', 281910), ('i', 248756), ('s', 243455), ('n', 235267), ('h', 233540), ('r', 230202), ('l', 166585), ('d', 145975), ('u', 126512), ('m', 109591), ('\\n', 107574), ('y', 93433), ('w', 88127), ('c', 85483), (',', 80860), ('f', 79113), ('.', 76515), ('g', 66802), ('b', 60715), ('p', 57060), ('v', 36990), ('k', 34777), (\"'\", 30890), (';', 17076), ('?', 10459), ('!', 8800), ('-', 7797), ('x', 5099), ('j', 4627), ('q', 3480), ('[', 1953), (']', 1948), (':', 1774), ('z', 1562), ('(', 595), (')', 594), ('\"', 450)] 4861240\n"
     ]
    }
   ],
   "source": [
    "c = Counter(text)\n",
    "print(c.most_common(100), np.sum([t[1] for t in c.most_common(100)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1664562951016613"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "809184/4861240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, ':': 10, ';': 11, '?': 12, '[': 13, ']': 14, 'a': 15, 'b': 16, 'c': 17, 'd': 18, 'e': 19, 'f': 20, 'g': 21, 'h': 22, 'i': 23, 'j': 24, 'k': 25, 'l': 26, 'm': 27, 'n': 28, 'o': 29, 'p': 30, 'q': 31, 'r': 32, 's': 33, 't': 34, 'u': 35, 'v': 36, 'w': 37, 'x': 38, 'y': 39, 'z': 40}\n"
     ]
    }
   ],
   "source": [
    "char_to_int = {k: v for k, v in zip(chars, range(len(chars)))}\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: ':', 11: ';', 12: '?', 13: '[', 14: ']', 15: 'a', 16: 'b', 17: 'c', 18: 'd', 19: 'e', 20: 'f', 21: 'g', 22: 'h', 23: 'i', 24: 'j', 25: 'k', 26: 'l', 27: 'm', 28: 'n', 29: 'o', 30: 'p', 31: 'q', 32: 'r', 33: 's', 34: 't', 35: 'u', 36: 'v', 37: 'w', 38: 'x', 39: 'y', 40: 'z'}\n"
     ]
    }
   ],
   "source": [
    "int_to_char = {k: v for v, k in char_to_int.items()}\n",
    "print(int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 42\n"
     ]
    }
   ],
   "source": [
    "# Add padding and end\n",
    "padding_code = len(int_to_char)\n",
    "int_to_char[padding_code] = ''\n",
    "end_code = len(int_to_char)\n",
    "int_to_char[end_code] = '\\n\\n'\n",
    "print(padding_code, end_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, char_to_code):\n",
    "    return [char_to_code[c] for c in text]\n",
    "\n",
    "def decode(text_encoded, code_to_char):\n",
    "    return ''.join([code_to_char[c] for c in text_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 32, 29, 27, 1, 20, 15, 23, 32, 19, 33, 34, 1, 17, 32, 19, 15, 34, 35, 32, 19, 33, 1, 37, 19, 1, 18, 19, 33, 23, 32, 19, 1, 23, 28, 17, 32, 19, 15, 33, 19, 7, 0, 34, 22, 15, 34, 1, 34, 22, 19, 32, 19, 16, 39, 1, 16, 19, 15, 35, 34, 39, 4, 33, 1, 32, 29, 33, 19, 1, 27, 23, 21, 22, 34, 1, 28, 19, 36, 19, 32, 1, 18, 23, 19, 7, 0, 16, 35, 34, 1, 15, 33, 1, 34, 22, 19, 1, 32, 23, 30, 19, 32, 1, 33, 22, 29, 35, 26, 18, 1, 16, 39, 1, 34, 23, 27, 19, 1, 18, 19, 17, 19, 15, 33, 19, 7, 0, 22, 23, 33, 1, 34, 19, 28, 18, 19, 32, 1, 22, 19, 23, 32, 1, 27, 23, 21, 22, 34, 1, 16, 19, 15, 32, 1, 22, 23, 33, 1, 27, 19, 27, 29, 32, 39, 10, 0, 16, 35, 34, 1, 34, 22, 29, 35, 1, 17, 29, 28, 34, 32, 15, 17, 34, 19, 18, 1, 34, 29, 1, 34, 22, 23, 28, 19, 1, 29, 37, 28, 1, 16, 32, 23, 21, 22, 34, 1, 19, 39, 19, 33, 7, 0, 20, 19, 19, 18, 4, 33, 34, 1, 34, 22, 39, 1, 26, 23, 21, 22, 34, 4, 33, 1, 20, 26, 15, 27, 19, 1, 37, 23, 34, 22, 1, 33, 19, 26, 20, 8, 33, 35, 16, 33, 34, 15, 28, 34, 23, 15, 26, 1, 20, 35, 19, 26, 7, 0, 27, 15, 25, 23, 28, 21, 1, 15, 1, 20, 15, 27, 23, 28, 19, 1, 37, 22, 19, 32, 19, 1, 15, 16, 35, 28, 18, 15, 28, 17, 19, 1, 26, 23, 19, 33, 7, 0, 34, 22, 39, 1, 33, 19, 26, 20, 1, 34, 22, 39, 1, 20, 29, 19, 7, 1, 34, 29, 1, 34, 22, 39, 1, 33, 37, 19, 19, 34, 1, 33, 19, 26, 20, 1, 34, 29, 29, 1, 17, 32, 35, 19, 26, 10, 0, 34, 22, 29, 35, 1, 34, 22, 15, 34, 1, 15, 32, 34, 1, 28, 29, 37, 1, 34, 22, 19, 1, 37, 29, 32, 26, 18, 4, 33, 1, 20, 32, 19, 33, 22, 1, 29, 32, 28, 15, 27, 19, 28, 34, 7, 0, 15, 28, 18, 1, 29, 28, 26, 39, 1, 22, 19, 32, 15, 26, 18, 1, 34, 29, 1, 34, 22, 19, 1, 21, 15, 35, 18, 39, 1, 33, 30, 32, 23, 28, 21, 7, 0, 37, 23, 34, 22, 23, 28, 1, 34, 22, 23, 28, 19, 1, 29, 37, 28, 1, 16, 35, 18, 1, 16, 35, 32, 23, 19, 33, 34, 1, 34, 22, 39, 1, 17, 29, 28, 34, 19, 28, 34, 7, 0, 15, 28, 18, 1, 34, 19, 28, 18, 19, 32, 1, 17, 22, 35, 32, 26, 1, 27, 15, 25, 4, 33, 34, 1, 37, 15, 33, 34, 19, 1, 23, 28, 1, 28, 23, 21, 21, 15, 32, 18, 23, 28, 21, 10, 0, 30, 23, 34, 39, 1, 34, 22, 19, 1, 37, 29, 32, 26, 18, 7, 1, 29, 32, 1, 19, 26, 33, 19, 1, 34, 22, 23, 33, 1, 21, 26, 35, 34, 34, 29, 28, 1, 16, 19, 7, 0, 34, 29, 1, 19, 15, 34, 1, 34, 22, 19, 1, 37, 29, 32, 26, 18, 4, 33, 1, 18, 35, 19, 7, 1, 16, 39, 1, 34, 22, 19, 1, 21, 32, 15, 36, 19, 1, 15, 28, 18, 1, 34, 22, 19, 19, 9]\n"
     ]
    }
   ],
   "source": [
    "sonnets_encoded = [encode(s, char_to_int) for s in sonnets]\n",
    "print(sonnets_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract windows with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 3\n",
    "window_size = 40\n",
    "padding_size = window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows(text_encoded, stride, window_size, padding_size, padding_code, end_code):\n",
    "    windows = []\n",
    "    # Pad\n",
    "    text_padded = [padding_code] * padding_size + text_encoded\n",
    "    # Extract windows\n",
    "    start_pos = 0\n",
    "    end_pos = window_size + 1\n",
    "    while end_pos < len(text_padded):\n",
    "        windows.append(text_padded[start_pos:end_pos])\n",
    "        start_pos += stride\n",
    "        end_pos += stride\n",
    "    # Add ending\n",
    "    windows.append(text_padded[-window_size:] + [end_code])\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1624100, 41)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([w for s in sonnets_encoded for w in extract_windows(s, stride, window_size, padding_size, padding_code, end_code)])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1624100,)\n"
     ]
    }
   ],
   "source": [
    "y = X[:, -1]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1624100, 40)\n"
     ]
    }
   ],
   "source": [
    "X = X[:, :-1]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM, CuDNNLSTM, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "n_samples = 500000\n",
    "num_classes = len(int_to_char)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 43)\n"
     ]
    }
   ],
   "source": [
    "y_cat = to_categorical(y[:n_samples])\n",
    "print(y_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 40)\n"
     ]
    }
   ],
   "source": [
    "X = X[:n_samples, :]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=1, verbose=1)\n",
    "save_best = ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 10)            430       \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 128)               71680     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                5547      \n",
      "=================================================================\n",
      "Total params: 77,657\n",
      "Trainable params: 77,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_size = 10\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_classes, output_dim=emb_size, input_length=window_size))\n",
    "model.add(CuDNNLSTM(128, return_sequences=False))\n",
    "#model.add(LSTM(128, return_sequences=False))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "450000/450000 [==============================] - 21s 46us/step - loss: 2.0048 - acc: 0.4061 - val_loss: 1.8443 - val_acc: 0.4572\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.84427, saving model to weights.01-1.84.hdf5\n",
      "Epoch 2/10\n",
      "450000/450000 [==============================] - 19s 42us/step - loss: 1.6542 - acc: 0.4999 - val_loss: 1.7533 - val_acc: 0.4811\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.84427 to 1.75335, saving model to weights.02-1.75.hdf5\n",
      "Epoch 3/10\n",
      "450000/450000 [==============================] - 19s 42us/step - loss: 1.5753 - acc: 0.5204 - val_loss: 1.7173 - val_acc: 0.4949\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.75335 to 1.71728, saving model to weights.03-1.72.hdf5\n",
      "Epoch 4/10\n",
      "450000/450000 [==============================] - 19s 42us/step - loss: 1.5356 - acc: 0.5310 - val_loss: 1.7069 - val_acc: 0.4956\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.71728 to 1.70685, saving model to weights.04-1.71.hdf5\n",
      "Epoch 5/10\n",
      "450000/450000 [==============================] - 19s 42us/step - loss: 1.5130 - acc: 0.5362 - val_loss: 1.6999 - val_acc: 0.5029\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.70685 to 1.69987, saving model to weights.05-1.70.hdf5\n",
      "Epoch 6/10\n",
      "450000/450000 [==============================] - 19s 42us/step - loss: 1.4995 - acc: 0.5392 - val_loss: 1.6943 - val_acc: 0.5046\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.69987 to 1.69431, saving model to weights.06-1.69.hdf5\n",
      "Epoch 7/10\n",
      "450000/450000 [==============================] - 19s 42us/step - loss: 1.4897 - acc: 0.5414 - val_loss: 1.6892 - val_acc: 0.5059\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.69431 to 1.68921, saving model to weights.07-1.69.hdf5\n",
      "Epoch 8/10\n",
      "450000/450000 [==============================] - 19s 41us/step - loss: 1.4820 - acc: 0.5438 - val_loss: 1.6899 - val_acc: 0.5077\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.68921\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71ac6ae208>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y_cat, epochs=10, batch_size=512, verbose=1, validation_split=0.1, callbacks=[early_stop, save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sonnet(seed='', max_len=200):\n",
    "    sonnet = seed\n",
    "    if not seed:\n",
    "        seed = np.array([[padding_code] * window_size])\n",
    "    elif len(seed) < window_size:\n",
    "        seed = np.array([[padding_code] * (window_size - len(seed)) + encode(seed, char_to_int)])\n",
    "    pred = -1\n",
    "    while pred != end_code and len(sonnet) < max_len:\n",
    "        pred = np.argmax(model.predict(seed))\n",
    "        sonnet += int_to_char[pred]\n",
    "    return sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fair yoooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n"
     ]
    }
   ],
   "source": [
    "print(gen_sonnet('fair y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
